servername: s30   # server name

project_name: FC4 # project name (for wandb)
exp_name: 'exp_1' # experiment name (for wandb)

# Environment
seed: 160122  # random seed (for reproducibility)
mode: train   # {train / test}
devices: 2    # ex) integer or list (2, [0,1,2,3]...)
              # N of process if accelerator is cpu
              # N of gpu if accelerator is gpu
backup_host: 'ciplab@165.132.106.202'
backup_target: '/media/ssd2/backups/Slot-IID/'


path:
  time_format: '%y%m%d_%H%M%S'
  date_time_model: '950112_hhmmss_modelname'
  log_root: '../logs'
  ckpt_root: '../ckpts'
  result_root: '../results'

  # path params
  # these params will be auto-initialized through utils.common.init_path function
  log_path: ~     # tensorboard or wandb
  ckpt_path: ~    # model & training state checkpoint
  result_path: ~  # visualization or else...

# Model
model:
  name: ~ # {model_name}
  ver: ~ # {model_ver}
  solver: ~ # {sorver_ver}

# Loading ckpt
load:
  load_state: false  # if true, load everything and continue training (training phase)
                     # if false, load only network parameters (testing phase)
  ckpt_path: ~  # ex) '../ckpts/220314_1317/refactor_testing_best_MAE_illum.pt'

# Logger for printing & saving (tensorboard & wandb)  
logger:
  use_wandb: true
  log_every_n_steps: 20

train:
  optimizer:
    adam:
      lr: 3e-4
      betas:
        - 0.9
        - 0.999
  scheduler:
    StepLR:
      step_size: 300
      gamma: 0.5
      verbose: true
    CosineAnnealingLR:
      T_max: 10
      eta_min: 1e-6
      verbose: true
    ReduceLROnPlateau:
      mode: 'min'
      factor: 0.1
      patience: 10
      verbose: true
      threshold: 0.0001
      threshold_mode: 'rel'
      cooldown: 0
      min_lr: 0
      eps: 1e-08
    monitor: 'train-total_loss'  # metric to monitor (only for ReduceLROnPlateau)

# List of loss terms for weighted sum (criterion.py)
criterion:
  l1_loss:
    mod: 'l1_loss'
    alpha: 1.
  cross_entropy:
    mod: 'cross_entropy'
    alpha: 1.
  angular_loss:
    mod: 'angular_loss'
    alpha: 1.